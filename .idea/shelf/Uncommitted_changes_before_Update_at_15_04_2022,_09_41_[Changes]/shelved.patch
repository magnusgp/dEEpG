Index: prepareData.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\n\nimport os, mne, time\nimport os.path\nfrom mne.io import read_raw_edf\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nimport torch, re, warnings\nimport pandas as pd\nimport numpy as np\nfrom scipy import signal, stats\nimport matplotlib.pyplot as plt\nfrom eegProcess import TUH_rename_ch, nonPipeline, spectrogramMake, slidingWindow, pipeline\nfrom braindecode.datasets import create_from_X_y\nfrom pipeline.raw_utils import labelInt, oneHotEncoder\n\nclass TUH_data:\n    def __init__(self):\n        pass\n\n    def findEdf(self,path):\n        ### Makes dictionary of all edf files\n        EEG_count = 0\n        EEG_dict = {}\n\n        for dirpath, dirnames, filenames in os.walk(path):\n            for filename in [f for f in filenames if f.endswith(\".edf\")]:\n                \"\"\"For every edf file found somewhere in the directory, it is assumed the folders hold the structure: \n                \".../id/patientId/sessionId/edfFile\".\n                Therefore the path is split backwards and the EEG_dict updated with the found ids/paths.\n                Furthermore it is expected that a csv file will always be found in the directory.\"\"\"\n                session_path_split=os.path.split(dirpath)\n                patient_path_split = os.path.split(session_path_split[0])\n                id_path_split=os.path.split(patient_path_split[0])\n                EEG_dict.update({EEG_count: {\"id\": id_path_split[1], \"patient_id\": patient_path_split[1], \"session\":  session_path_split[1],\n                                          \"path\": os.path.join(dirpath, filename),\"csvpath\": os.path.join(dirpath, os.path.splitext(filename)[0]+'.csv')}})\n                EEG_count+=1\n        self.EEG_dict = EEG_dict\n        self.EEG_count=EEG_count\n\n    def loadOneRaw(self,id):\n        return mne.io.read_raw_edf(self.EEG_dict[id][\"path\"], preload=True)\n        #return self.readRawEdf().read_raw_edf(self.EEG_dict[id][\"path\"], preload=True)\n\n    def loadAllRaw(self):\n        EEG_raw_dict={}\n        for id in range(self.EEG_count):\n            EEG_raw_dict[id] = self.loadOneRaw(id)\n        self.EEG_raw_dict=EEG_raw_dict\n\n    def readRawEdf(self, edfDict=None, tWindow=120, tStep=30,\n                   read_raw_edf_param={'preload': True, \"stim_channel\": \"auto\"}):\n        #### This function i copied from https://github.com/DavidEnslevNyrnberg/DTU_DL_EEG/blob/master/Transfer%20learning%20project/eegProcess.py##\n        try:\n            edfDict[\"rawData\"] = read_raw_edf(edfDict[\"path\"], **read_raw_edf_param)\n            edfDict[\"fS\"] = edfDict[\"rawData\"].info[\"sfreq\"]\n            t_start = edfDict[\"rawData\"].annotations.orig_time\n            if t_start.timestamp() <= 0:\n                edfDict[\"t0\"] = datetime.fromtimestamp(0, tz=timezone.utc)\n                t_last = edfDict[\"t0\"].timestamp() + edfDict[\"rawData\"]._last_time + 1 / edfDict[\"fS\"]\n                edfDict[\"tN\"] = datetime.fromtimestamp(t_last, tz=timezone.utc)\n            else:\n                t_last = t_start.timestamp() + edfDict[\"rawData\"]._last_time + 1 / edfDict[\"fS\"]\n                edfDict[\"t0\"] = t_start  # datetime.fromtimestamp(t_start.timestamp(), tz=timezone.utc)\n                edfDict[\"tN\"] = datetime.fromtimestamp(t_last, tz=timezone.utc)\n\n            edfDict[\"tWindow\"] = float(tWindow)  # width of EEG sample window, given in (sec)\n            edfDict[\"tStep\"] = float(tStep)  # step/overlap between EEG sample windows, given in (sec)\n\n        except:\n            print(\"error break please inspect:\\n %s\\n~~~~~~~~~~~~\" % edfDict[\"rawData\"].filenames[0])\n\n        return edfDict\n\n    def prep(self, saveDir):\n        tic = time.time()\n        subjects_TUAR19 = defaultdict(dict)\n        Xwindows=[]\n        Ywindows=[]\n        for k in range(len(self.EEG_dict)):\n            subjects_TUAR19[k] = {'path':self.EEG_dict[k]['path']}\n\n            proc_subject = subjects_TUAR19[k]\n            proc_subject = self.readRawEdf(proc_subject, tWindow=100, tStep=100*.25,read_raw_edf_param={'preload': True})\n\n            proc_subject[\"rawData\"] = TUH_rename_ch(proc_subject[\"rawData\"])\n            TUH_pick = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n                        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Cz'] #A1, A2 removed\n            proc_subject[\"rawData\"].pick_channels(ch_names=TUH_pick)\n            proc_subject[\"rawData\"].reorder_channels(TUH_pick)\n\n            if k == 0:\n                self.sfreq = proc_subject[\"rawData\"].info[\"sfreq\"]\n                self.ch_names = proc_subject[\"rawData\"].info[\"ch_names\"]\n\n\n            pipeline(proc_subject[\"rawData\"], cap_setup=\"standard_1005\", lpfq=1, hpfq=40, notchfq=60,\n                     downSam=250)\n\n            # Generate output windows for (X,y) as (tensor, label)\n            proc_subject[\"preprocessing_output\"] = slidingRawWindow(proc_subject, t_max=proc_subject[\"rawData\"].times[-1],\n                                                                 tStep=proc_subject[\"tStep\"], FFToverlap=0.75,\n                                                                 crop_fq=24,\n                                                                 annoDir=self.EEG_dict[k]['csvpath'],\n                                                                 localSave={\"sliceSave\": True,\n                                                                            \"saveDir\": saveDir + r'/tensor',\n                                                                            \"local_return\": False})\n\n            for window in proc_subject[\"preprocessing_output\"].values():\n                Xwindows.append(window[0])\n                Ywindows.append(window[1])\n                #Xraw=np.concatenate((Xraw,np.array([window[0]])))\n                #Y=np.concatenate((Y,np.array([window[1]])))\n\n        toc = time.time()\n        print(\"\\n~~~~~~~~~~~~~~~~~~~~\\n\"\n              \"it took %imin:%is to run preprocess-pipeline for %i patients\\n with window length [%.2fs] and t_step [%.2fs]\"\n              \"\\n~~~~~~~~~~~~~~~~~~~~\\n\"% (int((toc-tic)/60), int((toc-tic) % 60), len(subjects_TUAR19),\n                                           subjects_TUAR19[k][\"tWindow\"], subjects_TUAR19[k][\"tStep\"]))\n\n        self.Xwindows=Xwindows\n        self.Ywindows=Ywindows\n\ndef label_TUH(annoPath=False, window=[0,0], header=None): #saveDir=os.getcwd(),\n    df = pd.read_csv(annoPath, sep=\",\", skiprows=6, header=header)\n    df.fillna('null', inplace=True)\n    within_con0 = (df[2] <= window[0]) & (window[0] <= df[3])\n    within_con1 = (df[2] <= window[1]) & (window[1] <= df[3])\n    label_TUH = df[df[2].between(window[0], window[1]) |\n                   df[3].between(window[0], window[1]) |\n                   (within_con0 & within_con1)]\n    label_df = label_TUH.rename(columns={2: 't_start', 3: 't_end', 4: 'label', 5: 'confidence'})[\"label\"] #Renamer headers i pandas dataen\n    return_list = label_df.to_numpy().tolist() #Outputter kun listen af label navne i vinduet, fx [\"eyem\", \"null\"]\n    return return_list\n\ndef makeRawWindow(MNE_raw=None, t0=0, tWindow=120):\n    #take a raw signal and make a window given time specifications.\n    chWindows = MNE_raw.get_data(start=int(t0), stop=int(t0+tWindow), reject_by_annotation=\"omit\", picks=['eeg'])\n    return chWindows\n\ndef slidingRawWindow(EEG_series=None, t_max=0, tStep=1, FFToverlap=None, crop_fq=45, annoDir=None,\n                  localSave={\"sliceSave\":False, \"saveDir\":os.getcwd(), \"local_return\":False}):\n    # catch correct sample frequency and end sample\n    edf_fS = EEG_series[\"rawData\"].info[\"sfreq\"]\n    t_N = int(t_max*edf_fS)\n\n    # ensure window-overlaps progress in sample interger\n    if float(tStep*edf_fS) == float(int(tStep*edf_fS)):\n        t_overlap = int(tStep*edf_fS)\n    else:\n        t_overlap = int(tStep*edf_fS)\n        overlap_change = 100-(t_overlap/edf_fS)*100\n        print(\"\\n  tStep [%.3f], overlap does not equal an interger [%f] and have been rounded to %i\"\n              \"\\n  equaling to %.1f%% overlap or %.3fs time steps\\n\\n\"\n              % (tStep, tStep*edf_fS, t_overlap, overlap_change, t_overlap/edf_fS))\n\n    # initialize variables for segments\n    window_EEG = defaultdict(tuple)\n    window_width = int(EEG_series[\"tWindow\"]*edf_fS)\n    label_path = EEG_series['path'].split(\".edf\")[0] + \".csv\"\n\n    # segment all N-1 windows (by positive lookahead)\n    for i in range(0, t_N-window_width, t_overlap):\n        t_start = i/edf_fS\n        t_end = (i+window_width)/edf_fS\n        window_key = \"window_%.3fs_%.3fs\" % (t_start, t_end)\n        window_data = makeRawWindow(EEG_series[\"rawData\"], t0=i, tWindow=window_width) # , show_chan_num=0) #)\n        window_label = label_TUH(annoPath=label_path, window=[t_start, t_end])#, saveDir=annoDir)\n        window_EEG[window_key] = (window_data, window_label)\n    # window_N segments (by negative lookahead)\n    if t_N % t_overlap != 0:\n        t_start = (t_N - window_width)/edf_fS\n        t_end = t_N/edf_fS\n        window_key = \"window_%.3fs_%.3fs\" % (t_start, t_end)\n        window_data = makeRawWindow(EEG_series[\"rawData\"], t0=i, tWindow=window_width)\n        window_label = label_TUH(annoPath=label_path, window=[t_start, t_end])#, saveDir=annoDir)\n        window_EEG[window_key] = (window_data, window_label)\n\n    return window_EEG\n    # save in RAM, disk or not\n    \"\"\"    if localSave[\"sliceSave\"]:\n        idDir = EEG_series[\"rawData\"].filenames[0].split('\\\\')[-1].split('.')[0]\n        if not os.path.exists(localSave[\"saveDir\"] + \"tempData\\\\\"):\n            os.mkdir(localSave[\"saveDir\"] + \"tempData\\\\\")\n        if not os.path.exists(localSave[\"saveDir\"] + \"tempData\\\\\" + idDir):\n            os.mkdir(localSave[\"saveDir\"] + \"tempData\\\\\" + idDir)\n        for k, v in window_EEG.items():\n            torch.save(v, localSave[\"saveDir\"] + \"tempData\\\\%s\\\\%s.pt\" % (idDir, k)) # for np del torch.save\n    if not localSave[\"sliceSave\"] or localSave[\"local_return\"] is True:\n        windowOut = window_EEG.copy()\n    else:\n        windowOut = None\n    \n    return windowOut\"\"\"\n\ndef annotate_TUH(raw,annoPath=False, header=None):\n    df = pd.read_csv(annoPath, sep=\",\", skiprows=6, header=header)\n    t_start=df[2].to_numpy()\n    dura=df[3].to_numpy()-t_start\n    labels=df[4].to_numpy().tolist()\n\n    anno=mne.Annotations(onset=t_start.tolist(),\n                            duration=dura.tolist(),\n                              description=labels)\n\n    raw_anno=raw.set_annotations(anno)\n    return raw_anno\n\npath=\"TUH_data_sample\"\nsave_dir=os.getcwd()\nTUH=TUH_data()\nTUH.findEdf(path=path)\nprint(TUH.EEG_dict)\nTUH.loadAllRaw()\n\nraw_anno=annotate_TUH(TUH.EEG_raw_dict[0],annoPath=TUH.EEG_dict[0]['csvpath'])\nraw_anno.plot(start=689,duration=30)\nplt.show()\n\n#windows_dataset = create_from_X_y(\n #   TUH.Xwindows, labelInt(TUH.Ywindows), drop_last_window=True, sfreq=TUH.sfreq, ch_names=TUH.ch_names,\n  #  window_stride_samples=len(TUH.Xwindows[0][0]),\n   # window_size_samples=len(TUH.Xwindows[0][0]),\n#)\n\n#windows_dataset.description\n\n\n#TUH.EEG_raw_dict[0].plot(start=689,duration=10)\n#plt.show()\n\n#print(TUH.EEG_raw_dict)\n#TUH.EEG_raw_dict[0].plot_psd()\n#TUH.EEG_raw_dict[0].plot(duration=4)\n#plt.show()\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/prepareData.py b/prepareData.py
--- a/prepareData.py	(revision 5abf075f6366a276160052d8c41f12fb871c8d5b)
+++ b/prepareData.py	(date 1649242331388)
@@ -213,15 +213,15 @@
 print(TUH.EEG_dict)
 TUH.loadAllRaw()
 
-raw_anno=annotate_TUH(TUH.EEG_raw_dict[0],annoPath=TUH.EEG_dict[0]['csvpath'])
-raw_anno.plot(start=689,duration=30)
-plt.show()
+#raw_anno=annotate_TUH(TUH.EEG_raw_dict[0],annoPath=TUH.EEG_dict[0]['csvpath'])
+#raw_anno.plot(start=689,duration=30)
+#plt.show()
 
-#windows_dataset = create_from_X_y(
- #   TUH.Xwindows, labelInt(TUH.Ywindows), drop_last_window=True, sfreq=TUH.sfreq, ch_names=TUH.ch_names,
-  #  window_stride_samples=len(TUH.Xwindows[0][0]),
-   # window_size_samples=len(TUH.Xwindows[0][0]),
-#)
+windows_dataset = create_from_X_y(
+   TUH.Xwindows, oneHotEncoder(TUH.Ywindows), drop_last_window=True, sfreq=TUH.sfreq, ch_names=TUH.ch_names,
+    window_stride_samples=len(TUH.Xwindows[0][0]),
+    window_size_samples=len(TUH.Xwindows[0][0]),
+)
 
 #windows_dataset.description
 
Index: pipeline/preprocessFunctions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import mne\n\ndef preprocessRaw(MNE_raw=None, lpfq=1, hpfq=40, notchfq=60, downSam=100, cap_setup=\"easycap-M1\",ICA=False):\n    #The raw signal is Band-pass filtered. Default is 1-100 (as to not remove the muscle artifacts of\n    MNE_raw.filter(lpfq, hpfq, fir_design='firwin')\n\n    # Channel names are set from the cap_setup\n    MNE_raw.set_montage(mne.channels.make_standard_montage(kind=cap_setup, head_size=0.095), on_missing=\"warn\")\n\n    # In america there is a line-noise at around 60 Hz, which i\n    MNE_raw.notch_filter(freqs=notchfq, notch_widths=5)\n\n    # Step 7: Downsample\n    MNE_raw.resample(sfreq=downSam)\n\n    # Step 8\n    #MNE_raw.interpolate_bads(reset_bads=True, origin='auto')\n\n    # Re-reference the raw signal to average of all channels\n    MNE_raw.set_eeg_reference()\n\n    if ICA:\n        ica=mne.preprocessing.ICA(n_components=20)\n        ica.fit(MNE_raw)\n        MNE_raw.load_data()\n        ica.apply(MNE_raw)\n\n    return MNE_raw
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pipeline/preprocessFunctions.py b/pipeline/preprocessFunctions.py
--- a/pipeline/preprocessFunctions.py	(revision 5abf075f6366a276160052d8c41f12fb871c8d5b)
+++ b/pipeline/preprocessFunctions.py	(date 1649849829085)
@@ -1,6 +1,20 @@
 import mne
+import sklearn
+from sklearn.model_selection import train_test_split
+from sklearn.preprocessing import StandardScaler
+from sklearn.datasets import make_moons, make_circles, make_classification
+from sklearn.neural_network import MLPClassifier
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.svm import SVC
+from sklearn.gaussian_process import GaussianProcessClassifier
+from sklearn.gaussian_process.kernels import RBF
+from sklearn.tree import DecisionTreeClassifier
+from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
+from sklearn.naive_bayes import GaussianNB
+from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
 
-def preprocessRaw(MNE_raw=None, lpfq=1, hpfq=40, notchfq=60, downSam=100, cap_setup="easycap-M1",ICA=False):
+
+def simplePreprocess(MNE_raw=None, lpfq=1, hpfq=40, notchfq=60, downSam=100, cap_setup="easycap-M1"):
     #The raw signal is Band-pass filtered. Default is 1-100 (as to not remove the muscle artifacts of
     MNE_raw.filter(lpfq, hpfq, fir_design='firwin')
 
@@ -13,6 +27,12 @@
     # Step 7: Downsample
     MNE_raw.resample(sfreq=downSam)
 
+    return MNE_raw
+
+
+    # Step 7 1/2: Use classifier to identify bad channels - Naive Bayes
+
+def rereference(MNE_raw=None, ):
     # Step 8
     #MNE_raw.interpolate_bads(reset_bads=True, origin='auto')
 
Index: pipeline/raw_utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import tempfile\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport mne\n\nimport eegProcess\n\nfrom torch.utils.data import DataLoader, random_split\nfrom torch import Generator\n\nfrom braindecode.datasets import TUH\nfrom braindecode.preprocessing import (\n    preprocess, Preprocessor, create_fixed_length_windows, scale as multiply)\n\ndef select_by_duration(ds, tmin=0, tmax=None):\n    if tmax is None:\n        tmax = np.inf\n    # determine length of the recordings and select based on tmin and tmax\n    split_ids = []\n    for d_i, d in enumerate(ds.datasets):\n        duration = d.raw.n_times / d.raw.info['sfreq']\n        if tmin <= duration <= tmax:\n            split_ids.append(d_i)\n    splits = ds.split(split_ids)\n    split = splits['0']\n    return split\n\ndef select_by_channels(ds, ch_mapping):\n    split_ids = []\n    for i, d in enumerate(ds.datasets):\n        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n        # these are the channels we are looking for\n        seta = set(ch_mapping[ref].keys())\n        # these are the channels of the recording\n        setb = set(d.raw.ch_names)\n        # if recording contains all channels we are looking for, include it\n        if seta.issubset(setb):\n            split_ids.append(i)\n    #return ds.split(split_ids)['0']\n    return ds.split(split_ids)['0']\n\ndef custom_rename_channels(raw, mapping):\n    # rename channels which are dependent on referencing:\n    # le: EEG 01-LE, ar: EEG 01-REF\n    # mne fails if the mapping contains channels as keys that are not present\n    # in the raw\n    reference = raw.ch_names[0].split('-')[-1].lower()\n    assert reference in ['le', 'ref'], 'unexpected referencing'\n    reference = 'le' if reference == 'le' else 'ar'\n    raw.rename_channels(mapping[reference])\n\n\ndef custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n    # has lower duration than tmax\n    # by default mne fails if tmax is bigger than duration\n    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n\ndef raw2array(raw, preproc_params, win_params, window_size_samples=10 ,window_stride_samples=2, drop_last_window=True, save_path=None, preproc=False, manual_preproc=False):\n    \"\"\"\n    Convert raw EDF data to array.\n    \"\"\"\n    # Preprocess\n    if preproc:\n        raw = preprocess(\n            concat_ds=raw,\n            preprocessors=preproc_params,\n            n_jobs=1,\n            save_dir=save_path)\n    elif manual_preproc:\n        for i in range(len(preproc_params)):\n            preprocessor = Preprocessor(preproc_params[i])\n            #  Apply preprocessing\n            preprocessor.apply(raw)\n\n    # Create windows\n    if win_params is not None:\n        windows = create_fixed_length_windows(raw, win_params)\n    else:\n        windows = create_fixed_length_windows(raw, window_size_samples=window_size_samples, window_stride_samples=window_stride_samples, drop_last_window=drop_last_window)\n\n    # Save windows\n    if save_path is not None:\n        np.save(save_path, windows)\n\n    return windows\n\ndef oneHotEncoder(labels):\n    \"\"\"\n    Encode labels to one-hot encoding.\n    \"\"\"\n    all_labels = ['musc', 'eyem', 'elec', 'eyem_musc', 'musc_elec', 'chew', 'eyem_elev',\n                  'eyem_chew', 'shiv', 'chew_musc', 'elpp', 'chew_elec', 'eyem_shiv', 'shiv_elec']\n    n_classes = len(all_labels)\n    one_hot_labels = np.zeros((len(labels), n_classes))\n    for i in range(len(labels)):\n        for j, label in enumerate(labels):\n            if label in all_labels:\n                one_hot_labels[i, j] = 1\n    return one_hot_labels\n\ndef labelInt(labels):\n    all_labels = ['musc', 'eyem', 'elec', 'eyem_musc', 'musc_elec', 'chew', 'eyem_elev',\n                  'eyem_chew', 'shiv', 'chew_musc', 'elpp', 'chew_elec', 'eyem_shiv', 'shiv_elec']\n    encoded = []\n    for i in range(len(labels)):\n        for j in range(len(all_labels)):\n            if labels[i] == all_labels[j]:\n                encoded.append(j+1)\n    return encoded
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pipeline/raw_utils.py b/pipeline/raw_utils.py
--- a/pipeline/raw_utils.py	(revision 5abf075f6366a276160052d8c41f12fb871c8d5b)
+++ b/pipeline/raw_utils.py	(date 1649243516255)
@@ -96,9 +96,9 @@
     n_classes = len(all_labels)
     one_hot_labels = np.zeros((len(labels), n_classes))
     for i in range(len(labels)):
-        for j, label in enumerate(labels):
-            if label in all_labels:
-                one_hot_labels[i, j] = 1
+        for j, label in enumerate(labels[i]):
+            one_hot_labels[i][j] = 1 if label in all_labels else 0
+            #one_hot_labels[i, j] = 1 if label == all_labels[j] else 0
     return one_hot_labels
 
 def labelInt(labels):
Index: pipeline/loadFunctions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os, mne, time, re\nfrom mne.io import read_raw_edf\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nimport pandas as pd\nfrom preprocessFunctions import preprocessRaw\nimport matplotlib.pyplot as plt\nplt.rcParams[\"font.family\"] = \"Times New Roman\"\n\n##These functions are either inspired from or modified copies of code written by David Nyrnberg:\n# https://github.com/DavidEnslevNyrnberg/DTU_DL_EEG/tree/0bfd1a9349f60f44e6f7df5aa6820434e44263a2/Transfer%20learning%20project\n\n\nclass TUH_data:\n    def __init__(self, path):\n        ### Makes dictionary of all edf files\n        EEG_count = 0\n        EEG_dict = {}\n\n        for dirpath, dirnames, filenames in os.walk(path):\n            for filename in [f for f in filenames if f.endswith(\".edf\")]:\n                \"\"\"For every edf file found somewhere in the directory, it is assumed the folders hold the structure: \n                \".../id/patientId/sessionId/edfFile\".\n                Therefore the path is split backwards and the EEG_dict updated with the found ids/paths.\n                Furthermore it is expected that a csv file will always be found in the directory.\"\"\"\n                session_path_split = os.path.split(dirpath)\n                patient_path_split = os.path.split(session_path_split[0])\n                id_path_split = os.path.split(patient_path_split[0])\n                EEG_dict.update({EEG_count: {\"id\": id_path_split[1],\n                                             \"patient_id\": patient_path_split[1],\n                                             \"session\": session_path_split[1],\n                                             \"path\": os.path.join(dirpath, filename),\n                                             \"csvpath\": os.path.join(dirpath, os.path.splitext(filename)[0]+'.csv')}})\n                EEG_count += 1\n        self.EEG_dict = EEG_dict\n        self.EEG_count = EEG_count\n\n    \"\"\" These functions could probably be deleted, but are nice in case we want a quick plot of a raw file.\n    def loadOneRaw(self, id):\n        return mne.io.read_raw_edf(self.EEG_dict[id][\"path\"], preload=True)\n\n    def loadAllRaw(self):\n        EEG_raw_dict = {}\n        for id in range(self.EEG_count):\n            EEG_raw_dict[id] = self.loadOneRaw(id)\n        self.EEG_raw_dict = EEG_raw_dict\n        \"\"\"\n\n    def readRawEdf(self, edfDict=None, tWindow=120, tStep=30,\n                   read_raw_edf_param={'preload': True, \"stim_channel\": \"auto\"}):\n        try:\n            edfDict[\"rawData\"] = read_raw_edf(edfDict[\"path\"], **read_raw_edf_param)\n            edfDict[\"fS\"] = edfDict[\"rawData\"].info[\"sfreq\"]\n            t_start = edfDict[\"rawData\"].annotations.orig_time\n            if t_start.timestamp() <= 0:\n                edfDict[\"t0\"] = datetime.fromtimestamp(0, tz=timezone.utc)\n                t_last = edfDict[\"t0\"].timestamp() + edfDict[\"rawData\"]._last_time + 1 / edfDict[\"fS\"]\n                edfDict[\"tN\"] = datetime.fromtimestamp(t_last, tz=timezone.utc)\n            else:\n                t_last = t_start.timestamp() + edfDict[\"rawData\"]._last_time + 1 / edfDict[\"fS\"]\n                edfDict[\"t0\"] = t_start  # datetime.fromtimestamp(t_start.timestamp(), tz=timezone.utc)\n                edfDict[\"tN\"] = datetime.fromtimestamp(t_last, tz=timezone.utc)\n\n            edfDict[\"tWindow\"] = float(tWindow)  # width of EEG sample window, given in (sec)\n            edfDict[\"tStep\"] = float(tStep)  # step/overlap between EEG sample windows, given in (sec)\n\n        except:\n            print(\"error break please inspect:\\n %s\\n~~~~~~~~~~~~\" % edfDict[\"rawData\"].filenames[0])\n\n        return edfDict\n\n    def prep(self,tWindow=100, tStep=100 * .25,plot=False):\n        tic = time.time()\n        subjects_TUAR19 = defaultdict(dict)\n        Xwindows = []\n        Ywindows = []\n        for k in range(len(self.EEG_dict)):\n            subjects_TUAR19[k] = {'path': self.EEG_dict[k]['path']}\n\n            proc_subject = subjects_TUAR19[k]\n            proc_subject = self.readRawEdf(proc_subject, tWindow=tWindow, tStep=tStep,\n                                           read_raw_edf_param={'preload': True})\n\n            proc_subject[\"rawData\"] = TUH_rename_ch(proc_subject[\"rawData\"])\n            TUH_pick = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n                        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Cz']  # A1, A2 removed\n            proc_subject[\"rawData\"].pick_channels(ch_names=TUH_pick)\n            proc_subject[\"rawData\"].reorder_channels(TUH_pick)\n\n            if k == 0 and plot:\n                    raw_anno = annotate_TUH(proc_subject[\"rawData\"],annoPath=self.EEG_dict[k][\"csvpath\"])\n                    raw_anno.plot()\n                    plt.show()\n\n            preprocessRaw(proc_subject[\"rawData\"], cap_setup=\"standard_1005\", lpfq=1, hpfq=40, notchfq=60,\n                     downSam=250)\n            if k == 0:\n                self.sfreq = proc_subject[\"rawData\"].info[\"sfreq\"]\n                self.ch_names = proc_subject[\"rawData\"].info[\"ch_names\"]\n                if plot:\n                    raw_anno = annotate_TUH(proc_subject[\"rawData\"], annoPath=self.EEG_dict[k][\"csvpath\"])\n                    raw_anno.plot()\n                    plt.show()\n\n            # Generate output windows for (X,y) as (array, label)\n            proc_subject[\"preprocessing_output\"] = slidingRawWindow(proc_subject,\n                                                                    t_max=proc_subject[\"rawData\"].times[-1],\n                                                                    tStep=proc_subject[\"tStep\"])\n\n            for window in proc_subject[\"preprocessing_output\"].values():\n                Xwindows.append(window[0])\n                Ywindows.append(window[1])\n\n        toc = time.time()\n        print(\"\\n~~~~~~~~~~~~~~~~~~~~\\n\"\n              \"it took %imin:%is to run preprocess-pipeline for %i patients\\n with window length [%.2fs] and t_step [%.2fs]\"\n              \"\\n~~~~~~~~~~~~~~~~~~~~\\n\" % (int((toc - tic) / 60), int((toc - tic) % 60), len(subjects_TUAR19),\n                                            tWindow, tStep))\n\n        self.Xwindows = Xwindows\n        self.Ywindows = Ywindows\n\n# renames TUH channels to conventional 10-20 system\ndef TUH_rename_ch(MNE_raw=False):\n    # MNE_raw\n    # mne.channels.rename_channels(MNE_raw.info, {\"PHOTIC-REF\": \"PROTIC\"})\n    for i in MNE_raw.info[\"ch_names\"]:\n        reSTR = r\"(?<=EEG )(\\S*)(?=-REF)\"  # working reSTR = r\"(?<=EEG )(.*)(?=-REF)\"\n        reLowC = ['FP1', 'FP2', 'FZ', 'CZ', 'PZ']\n\n        if re.search(reSTR, i) and re.search(reSTR, i).group() in reLowC:\n            lowC = i[0:5]+i[5].lower()+i[6:]\n            mne.channels.rename_channels(MNE_raw.info, {i: re.findall(reSTR, lowC)[0]})\n        elif i == \"PHOTIC-REF\":\n            mne.channels.rename_channels(MNE_raw.info, {i: \"PHOTIC\"})\n        elif re.search(reSTR, i):\n            mne.channels.rename_channels(MNE_raw.info, {i: re.findall(reSTR, i)[0]})\n        else:\n            continue\n            # print(i)\n    print(MNE_raw.info[\"ch_names\"])\n    return MNE_raw\n\ndef label_TUH(annoPath=False, window=[0, 0], header=None):  # saveDir=os.getcwd(),\n    df = pd.read_csv(annoPath, sep=\",\", skiprows=6, header=header)\n    df.fillna('null', inplace=True)\n    within_con0 = (df[2] <= window[0]) & (window[0] <= df[3])\n    within_con1 = (df[2] <= window[1]) & (window[1] <= df[3])\n    label_TUH = df[df[2].between(window[0], window[1]) |\n                   df[3].between(window[0], window[1]) |\n                   (within_con0 & within_con1)]\n    label_df = label_TUH.rename(columns={2: 't_start', 3: 't_end', 4: 'label', 5: 'confidence'})[\"label\"]  # Renamer headers i pandas dataen\n    return_list = label_df.to_numpy().tolist()  # Outputter kun listen af label navne i vinduet, fx [\"eyem\", \"null\"]\n    return return_list\n\n\ndef makeArrayWindow(MNE_raw=None, t0=0, tWindow=120):\n    # take a raw signal and make a window given time specifications. Outputs an array, because of raw.get_data().\n    chWindows = MNE_raw.get_data(start=int(t0), stop=int(t0 + tWindow), reject_by_annotation=\"omit\", picks=['eeg'])\n    return chWindows\n\n\ndef slidingRawWindow(EEG_series=None, t_max=0, tStep=1):\n    # catch correct sample frequency and end sample\n    edf_fS = EEG_series[\"rawData\"].info[\"sfreq\"]\n    t_N = int(t_max * edf_fS)\n\n    # ensure window-overlaps progress in sample interger\n    if float(tStep * edf_fS) == float(int(tStep * edf_fS)):\n        t_overlap = int(tStep * edf_fS)\n    else:\n        t_overlap = int(tStep * edf_fS)\n        overlap_change = 100 - (t_overlap / edf_fS) * 100\n        print(\"\\n  tStep [%.3f], overlap does not equal an interger [%f] and have been rounded to %i\"\n              \"\\n  equaling to %.1f%% overlap or %.3fs time steps\\n\\n\"\n              % (tStep, tStep * edf_fS, t_overlap, overlap_change, t_overlap / edf_fS))\n\n    # initialize variables for segments\n    window_EEG = defaultdict(tuple)\n    window_width = int(EEG_series[\"tWindow\"] * edf_fS)\n    label_path = EEG_series['path'].split(\".edf\")[0] + \".csv\"\n\n    # segment all N-1 windows (by positive lookahead)\n    for i in range(0, t_N - window_width, t_overlap):\n        t_start = i / edf_fS\n        t_end = (i + window_width) / edf_fS\n        window_key = \"window_%.3fs_%.3fs\" % (t_start, t_end)\n        window_data = makeArrayWindow(EEG_series[\"rawData\"], t0=i, tWindow=window_width)  # , show_chan_num=0) #)\n        window_label = label_TUH(annoPath=label_path, window=[t_start, t_end])  # , saveDir=annoDir)\n        window_EEG[window_key] = (window_data, window_label)\n    # window_N segments (by negative lookahead)\n    if t_N % t_overlap != 0:\n        t_start = (t_N - window_width) / edf_fS\n        t_end = t_N / edf_fS\n        window_key = \"window_%.3fs_%.3fs\" % (t_start, t_end)\n        window_data = makeArrayWindow(EEG_series[\"rawData\"], t0=i, tWindow=window_width)\n        window_label = label_TUH(annoPath=label_path, window=[t_start, t_end])  # , saveDir=annoDir)\n        window_EEG[window_key] = (window_data, window_label)\n\n    return window_EEG\n\ndef plotWindow(EEG_series,label=\"null\", t_max=0, t_step=1):\n    edf_fS = EEG_series[\"rawData\"].info[\"sfreq\"]\n    t_N = int(t_max * edf_fS)\n    window_width = int(EEG_series[\"tWindow\"] * edf_fS)\n    label_path = EEG_series['path'].split(\".edf\")[0] + \".csv\"\n\n    for i in range(0, t_N - window_width, t_overlap):\n        t_start = i / edf_fS\n        t_end = (i + window_width) / edf_fS\n        window_label = label_TUH(annoPath=label_path, window=[t_start, t_end])\n        if len(window_label)==1 & window_label[0]==label:\n            EEG_series[\"rawData\"].plot(t_start=t_start, t_end=t_end)\n\ndef annotate_TUH(raw,annoPath=False, header=None):\n    df = pd.read_csv(annoPath, sep=\",\", skiprows=6, header=header)\n    t_start=df[2].to_numpy()\n    dura=df[3].to_numpy()-t_start\n    labels=df[4].to_numpy().tolist()\n    chan_names=df[1].to_numpy().tolist()\n    t_start=t_start.tolist()\n    dura=dura.tolist()\n\n    delete=[]\n    low_char={'FP1':'Fp1', 'FP2':'Fp2', 'FZ':'Fz', 'CZ':'Cz', 'PZ':'Pz'}\n    for i in range(len(chan_names)):\n        #remove numbers behind channel names:\n        chan_names[i]=[chan_names[i][:-3]]\n        # Change certain channels to have smaller letters:\n        if chan_names[i][0] in low_char:\n            chan_names[i][0]=low_char[chan_names[i][0]]\n\n        if chan_names[i][0] not in raw.ch_names:\n            delete.append(i)\n\n    #removes every annotation that cannot be handled backwards:\n    for ele in sorted(delete,reverse=True):\n        print(f\"Annotation {labels[ele]} on non-existing channel {chan_names[ele]} removed from annotations.\")\n        del t_start[ele], dura[ele],labels[ele],chan_names[ele]\n\n    anno=mne.Annotations(onset=t_start,\n                            duration=dura,\n                              description=labels,\n                                ch_names=chan_names)\n\n    raw_anno=raw.set_annotations(anno)\n    return raw_anno
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pipeline/loadFunctions.py b/pipeline/loadFunctions.py
--- a/pipeline/loadFunctions.py	(revision 5abf075f6366a276160052d8c41f12fb871c8d5b)
+++ b/pipeline/loadFunctions.py	(date 1649850114093)
@@ -3,7 +3,7 @@
 from collections import defaultdict
 from datetime import datetime, timezone
 import pandas as pd
-from preprocessFunctions import preprocessRaw
+from preprocessFunctions import simplePreprocess
 import matplotlib.pyplot as plt
 plt.rcParams["font.family"] = "Times New Roman"
 
@@ -244,4 +244,5 @@
                                 ch_names=chan_names)
 
     raw_anno=raw.set_annotations(anno)
-    return raw_anno
\ No newline at end of file
+    return raw_anno
+
Index: pipeline/loadData.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from loadFunctions import TUH_data\nfrom braindecode.datasets import create_from_X_y\n\n# Define path of outer directory for samples:\npath=\"../TUH_data_sample\"\n# Define folder for potential saves:\nsave_dir=\"D:/fagprojekt\"\n\n# Create class for data and find all edf files in path, and save in EEG_dict:\nTUH=TUH_data(path=path)\n\n# Load edf to raw, preprocess, make Xwindows (all windows as arrays) and Ywindows (labels as list of strings)\nTUH.prep(tWindow=100, tStep=100 * .25,plot=True)\n\n# Make Braindecode windows dataset from Xwindows and Ywindows:\nwindows_dataset = create_from_X_y(\n    TUH.Xwindows, TUH.Ywindows, drop_last_window=False, sfreq=TUH.sfreq, ch_names=TUH.ch_names,\n    window_stride_samples=len(TUH.Xwindows[0][0]),\n    window_size_samples=len(TUH.Xwindows[0][0]),\n)\n\nwindows_dataset.description\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pipeline/loadData.py b/pipeline/loadData.py
--- a/pipeline/loadData.py	(revision 5abf075f6366a276160052d8c41f12fb871c8d5b)
+++ b/pipeline/loadData.py	(date 1649849829069)
@@ -1,5 +1,6 @@
 from loadFunctions import TUH_data
 from braindecode.datasets import create_from_X_y
+from raw_utils import oneHotEncoder
 
 # Define path of outer directory for samples:
 path="../TUH_data_sample"
@@ -10,11 +11,11 @@
 TUH=TUH_data(path=path)
 
 # Load edf to raw, preprocess, make Xwindows (all windows as arrays) and Ywindows (labels as list of strings)
-TUH.prep(tWindow=100, tStep=100 * .25,plot=True)
+TUH.prep(tWindow=100, tStep=100 * .25, plot=True)
 
 # Make Braindecode windows dataset from Xwindows and Ywindows:
 windows_dataset = create_from_X_y(
-    TUH.Xwindows, TUH.Ywindows, drop_last_window=False, sfreq=TUH.sfreq, ch_names=TUH.ch_names,
+    TUH.Xwindows, oneHotEncoder(TUH.Ywindows), drop_last_window=False, sfreq=TUH.sfreq, ch_names=TUH.ch_names,
     window_stride_samples=len(TUH.Xwindows[0][0]),
     window_size_samples=len(TUH.Xwindows[0][0]),
 )
Index: pipeline/classifierFunctions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pipeline/classifierFunctions.py b/pipeline/classifierFunctions.py
new file mode 100644
--- /dev/null	(date 1649861746775)
+++ b/pipeline/classifierFunctions.py	(date 1649861746775)
@@ -0,0 +1,75 @@
+import mne
+import sklearn
+from sklearn.model_selection import train_test_split
+from sklearn.preprocessing import StandardScaler
+from sklearn.datasets import make_moons, make_circles, make_classification
+from sklearn.neural_network import MLPClassifier
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.svm import SVC
+from sklearn.gaussian_process import GaussianProcessClassifier
+from sklearn.gaussian_process.kernels import RBF
+from sklearn.tree import DecisionTreeClassifier
+from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
+from sklearn.naive_bayes import GaussianNB
+from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
+
+from loadFunctions import slidingRawWindow, TUH_data
+
+def badChannelClf(X=None, y=None, clf = None):
+    # Classify bad channels based on their MNE info
+    names = [
+        "Nearest Neighbors",
+        "Linear SVM",
+        "RBF SVM",
+        "Gaussian Process",
+        "Decision Tree",
+        "Random Forest",
+        "Neural Net",
+        "AdaBoost",
+        "Naive Bayes",
+        "QDA",
+    ]
+
+    clflist = [
+    KNeighborsClassifier(3),
+    SVC(kernel="linear", C=0.025),
+    SVC(gamma=2, C=1),
+    GaussianProcessClassifier(1.0 * RBF(1.0)),
+    DecisionTreeClassifier(max_depth=5),
+    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
+    MLPClassifier(alpha=1, max_iter=1000),
+    AdaBoostClassifier(),
+    GaussianNB(),
+    QuadraticDiscriminantAnalysis(),
+    ]
+
+    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
+
+    model = []
+    score = 0
+    for i in range(len(clf)):
+        # Check if the given classifier exists in the list
+        if clf[i] in names:
+            for name, clf in zip(names, clflist):
+                # Make classifier
+                clf.fit(X_train, y_train)
+                print("Score of the model {} is {} % ".format(name, clf.score(X_test, y_test)*100))
+
+                if clf.score(X_test, y_test) > score:
+                    score = clf.score(X_test, y_test)
+                    model = clf
+        else:
+            print("Please choose a classifier from the list: {}".format(names))
+
+        #MNE_raw_bads = []
+
+        #clf.predict(MNE_raw)
+
+    return model
+
+if __name__ == "__main__":
+    # test preprepoc function with MNE raw signal object
+    from loadFunctions import TUH_data
+    TUH = TUH_data(path="../TUH_data_sample")
+    X, y = TUH.electrodeClassifierPrep(tWindow=100, tStep=100 * .25, plot=False)
+    badChannelClf(X, y, clf=["Nearest Neighbors"])
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.10\" project-jdk-type=\"Python SDK\" />\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 5abf075f6366a276160052d8c41f12fb871c8d5b)
+++ b/.idea/misc.xml	(date 1649843059773)
@@ -1,4 +1,4 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.10" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.8" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
